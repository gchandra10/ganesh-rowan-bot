import os, streamlit as st

st.set_page_config(
    page_title="Ganesh Chandrasekaran :: AI Course Assistant – Rowan University",
    page_icon=":university:",
    layout="centered"
)

from openai import OpenAI
from databricks.vector_search.client import VectorSearchClient

# Consider reading from environment or Streamlit secrets
DATABRICKS_HOST = st.secrets.get("DATABRICKS_HOST") 
DATABRICKS_TOKEN = st.secrets.get("DATABRICKS_TOKEN")
VS_ENDPOINT = st.secrets.get("VS_ENDPOINT")
VS_INDEX = st.secrets.get("VS_INDEX")
LLM_MODEL = st.secrets.get("LLM_MODEL")

with open("styles.css", "r") as f:
    CUSTOM_CSS = f"<style>{f.read()}</style>"

st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

st.caption("Build: 0.12")

st.markdown("""
    <h1 class="page-title">Ganesh Chandrasekaran – Course Assistant</h1>
    <p style="color: var(--text-main); margin-top: 0.15rem; font-size: 1rem;">
    Supporting students in my <strong>Rowan University</strong> courses
    </p>
""", unsafe_allow_html=True)

st.markdown(
    """
    <div class="notice-box">
    <strong>Purpose.</strong> This tool is not a replacement for general purpose AI systems.
    It is built exclusively for students in <strong>Ganesh Chandrasekaran’s</strong> courses
    and relies solely on the course materials provided.<br><br>
    Please use it responsibly and verify answers with official course resources.
    </div>
    """,
    unsafe_allow_html=True,
)

st.markdown('<div class="spacer"></div>', unsafe_allow_html=True)

question = st.text_area(
    "Ask a question about the courses, prerequisites, syllabus, grading, assignments, final project, AI policy, or recommended tools to learn.",
    key="question_box",
)

col_ask, col_clear = st.columns([3, 1])

def clear_question():
    st.session_state["question_box"] = ""

def _normalize_vs_results(res):
    # Handle common response shapes; return list[dict]
    if isinstance(res, dict) and isinstance(res.get("data"), list):
        return res["data"]

    if isinstance(res, dict) and "result" in res:
        manifest = res.get("manifest") or {}
        cols_obj = manifest.get("columns") or manifest.get("column_names") or []
        cols = [c["name"] if isinstance(c, dict) and "name" in c else str(c) for c in cols_obj]
        result = res.get("result") or {}
        data_array = result.get("data_array") or result.get("data")
        if data_array and cols:
            rows = []
            for arr in data_array:
                rows.append({cols[i]: arr[i] for i in range(min(len(cols), len(arr)))})
            return rows
        if result.get("row_count", 0) == 0:
            return []
    return []

with col_ask:
    ask_clicked = st.button("ASK", key="ask_btn", use_container_width=True)

with col_clear:
    st.button(
        "CLEAR",
        key="clear_btn",
        on_click=clear_question,
        use_container_width=True,
    )

st.markdown(
    """
        <div class="notice-box">
        <strong>Disclaimer.</strong> This response is generated by an AI system using documents
        provided for some of the recent courses. The system is in early development. If you are
        unsure about the answer or need clarity for academic or policy decisions, contact
        <strong>Ganesh Chandrasekaran</strong> directly.
        </div>
    """,
    unsafe_allow_html=True,
)

if ask_clicked and st.session_state.question_box.strip():
    try:
        with st.spinner("Searching and answering..."):
            # Vector Search
            vsc = VectorSearchClient(
                workspace_url=DATABRICKS_HOST,
                personal_access_token=DATABRICKS_TOKEN,
                disable_notice=True
            )
            index = vsc.get_index(VS_ENDPOINT, VS_INDEX)
            res = index.similarity_search(
                query_text=st.session_state.question_box,
                columns=["title","url_or_path","chunk_text","section","page","doc_id"],
                num_results=5
            )
            rows = _normalize_vs_results(res)
            if not rows:
                st.warning("No matching passages. Try rephrasing or contact Professor Ganesh Chandrasekaran for help.")
                st.stop()

            # Build context
            contexts = []
            for row in rows:
                title = row.get("title") or ""
                url = row.get("url_or_path") or ""
                page = row.get("page")
                cite = f"{title} — {url}".strip(" —")
                if page:
                    cite += f" (p.{page})"
                chunk = row.get("chunk_text") or ""
                contexts.append(f"[Source] {cite}\n{chunk}")
            rag_context = "\n\n".join(contexts)

            client = OpenAI(
                api_key=DATABRICKS_TOKEN,
                base_url=f"{DATABRICKS_HOST.rstrip('/')}/serving-endpoints"
            )
            prompt = (
                "Answer using ONLY the context. Keep the sources title separately so it can be referenced." 
                "If the context does not contain the answer, say you don't know and contact Ganesh Chandrasekaran directly.\n\n"
                f"Question: {question}\n\nContext:\n{rag_context}"
            )
            out = client.chat.completions.create(
                model=LLM_MODEL,
                messages=[{"role":"user","content":prompt}],
                temperature=0.2
            )
        
        st.markdown("### Answer")
        #st.write(out.choices[0].message.content)
        st.markdown(f"**{out.choices[0].message.content}**", unsafe_allow_html=False)

        st.markdown("### Sources")
        for row in rows:
            t = row.get("title") or ""
            if t:
                st.markdown(f"- [{t}]")

    except Exception as e:
        st.exception(e)